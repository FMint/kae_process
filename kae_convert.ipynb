{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bvh2smpl\n",
    "\n",
    "import logging\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import smplx\n",
    "from bvh import Bvh\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import pdb\n",
    "import math\n",
    " \n",
    "# import bvh_tool, \n",
    "# import quat\n",
    " \n",
    "names = [\n",
    "    \"Hips\",\n",
    "    \"LeftUpLeg\",\n",
    "    \"RightUpLeg\",\n",
    "    \"Spine1\",\n",
    "    \"LeftLeg\",\n",
    "    \"RightLeg\",\n",
    "    \"Spine2\",\n",
    "    \"LeftFoot\",#\n",
    "    \"RightFoot\",\n",
    "    \"Spine3\",\n",
    "    \"LeftFoot\",#\n",
    "    \"RightFoot\",\n",
    "    \"Neck\",\n",
    "    \"LeftShoulder\",\n",
    "    \"RightShoulder\",\n",
    "    \"Head\",\n",
    "    \"LeftArm\",\n",
    "    \"RightArm\",\n",
    "    \"LeftForeArm\",\n",
    "    \"RightForeArm\",\n",
    "    \"LeftHand\",\n",
    "    \"RightHand\",\n",
    "]\n",
    "def bvh_to_smplx(bvh_file, n_frames=None,scale_v=1):\n",
    "    with open(bvh_file, 'r') as f:\n",
    "        mocap = Bvh(f.read())\n",
    " \n",
    "    if n_frames is None:\n",
    "        num_frames = len(mocap.frames)\n",
    "    else:\n",
    "        num_frames = min(n_frames, len(mocap.frames))\n",
    " \n",
    "    smplx_poses = np.zeros((num_frames, 24*3))\n",
    "    smplx_trans = np.zeros((num_frames, 3))\n",
    " \n",
    "    bvh_joint_names = set(mocap.get_joints_names())\n",
    " \n",
    "    for joint_index, joint_name in enumerate(mocap.get_joints_names()):\n",
    "        print(joint_name, joint_index)\n",
    " \n",
    "    # 定义一个绕x转90°，再绕y转90°的旋转，用于校正BVH与SMPLX坐标系的差异（z朝前，x朝左，y朝上）\n",
    "    rotation_correction = R.from_euler('XYZ', [90, 90, 0], degrees=True)\n",
    " \n",
    "    for i in range(num_frames):\n",
    "        print('Processing frame {}/{}'.format(i, num_frames), end='\\r')\n",
    "        for joint_index,joint_name in enumerate(names):\n",
    "            if joint_name not in bvh_joint_names:\n",
    "                logging.error(f'not joint_name:{joint_name}')\n",
    "                exit(123)\n",
    " \n",
    "            rotation = R.from_euler('YXZ', mocap.frame_joint_channels(i, joint_name, ['Yrotation','Xrotation','Zrotation' ]), degrees=True)\n",
    " \n",
    "            # 仅对根关节（Hips）应用朝向校正\n",
    "            if joint_name in ['Pelvis1','Hips']:\n",
    "                # rotation = rotation * rotation_correction\n",
    "                rotation = rotation_correction * rotation\n",
    " \n",
    "            smplx_poses[i,  3*joint_index:3 * (joint_index + 1)] = rotation.as_rotvec()\n",
    " \n",
    "            # 提取根关节平移\n",
    "            if joint_name in ['Pelvis','Hips']:\n",
    "                x, y, z = mocap.frame_joint_channels(i, joint_name, [ 'Xposition','Yposition', 'Zposition'])\n",
    "                smplx_trans[i] = np.array([x,y, z])\n",
    " \n",
    "    # 应用朝向校正\n",
    "    # smplx_trans = rotation_correction_trans.apply(smplx_trans)\n",
    " \n",
    "    # 反转Y轴平移方向\n",
    "    # smplx_trans[:, 1] *= -1\n",
    " \n",
    "    # 应用整体缩放\n",
    "    smplx_trans /=scale_v\n",
    " \n",
    "    return smplx_trans, smplx_poses\n",
    " \n",
    " \n",
    "def save_npz(output_file, smplx_trans, smplx_poses, gender='neutral', model_type='smplx', frame_rate=30):\n",
    "    np.savez(output_file, trans=smplx_trans, poses=smplx_poses, gender=gender, surface_model_type=model_type,\n",
    "             mocap_frame_rate=frame_rate, betas=np.zeros(16))\n",
    " \n",
    " \n",
    "\n",
    "bvh_file = \"D:\\\\fsy\\\\project\\\\kdae\\\\F01A1V1.bvh\"\n",
    "output_file = \"D:\\\\fsy\\\\project\\\\kdae\\\\F01A1V1.npz\"\n",
    "fps=30\n",
    "scale_v=100.0\n",
    "model_path=r\"D:\\fsy\\project\\smpl_model\"\n",
    "model = smplx.create(model_path=model_path, model_type=\"smpl\", gender=\"FEMALE\", batch_size=1)\n",
    "\n",
    "parents = model.parents.detach().cpu().numpy()\n",
    "\n",
    "# You can define betas like this.(default betas are 0 at all.)\n",
    "rest = model(  # betas = torch.randn([1, num_betas], dtype=torch.float32)\n",
    ")\n",
    "rest_pose = rest.joints.detach().cpu().numpy().squeeze()[:24, :]\n",
    "\n",
    "root_offset = rest_pose[0]\n",
    "offsets = rest_pose - rest_pose[parents]\n",
    "offsets[0] = root_offset\n",
    "offsets *= scale_v\n",
    "\n",
    "trans, rots_o = bvh_to_smplx(bvh_file, n_frames=600,scale_v=scale_v)\n",
    "\n",
    "# rots = rots_o.reshape(rots_o.shape[0], -1, 3)\n",
    "# print(rots_o.shape)\n",
    "# print(rots.shape)\n",
    "# rots = quat.from_axis_angle(rots)\n",
    "N=rots_o.shape[0]\n",
    "J=24\n",
    "rots = rots_o.reshape(-1, 3)          # (N*J, 3)\n",
    "quat = R.from_rotvec(rots).as_quat()  # 返回 (N*J, 4)  x,y,z,w\n",
    "quat = np.array(quat).reshape(N, J, 4)\n",
    "# print(quat.shape)\n",
    "\n",
    "order = \"yxz\"  #rotation顺序\n",
    "pos = offsets[None].repeat(N, axis=0)\n",
    "positions = pos.copy()\n",
    "positions[:, 0] = trans*scale_v\n",
    "# rotations = np.degrees(quat.as_euler('yxz'))\n",
    "rotations = R.from_quat(quat.reshape(-1,4)).as_euler(order, degrees=True).reshape(N, J, 3)\n",
    "# print(rotations.shape)\n",
    "\n",
    "bvh_data = {\"rotations\": rotations, \"positions\": positions, \"offsets\": offsets, \"parents\": parents, \"names\": names, \"order\": order, \"frametime\": 1 / fps}\n",
    "\n",
    "# output = \"0308.bvh\"\n",
    "\n",
    "# bvh_tool.save(output, bvh_data)\n",
    "\n",
    "print('frame_rate: ', fps)\n",
    "save_npz(output_file, trans, rots, frame_rate=20)\n",
    "\n",
    "out = {\"poses\": rots_o, \"trans\": trans, \"offsets\": offsets, \"parents\": parents}\n",
    "pickle.dump(out, open(f\"test3.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a162e04",
   "metadata": {},
   "source": [
    "data包含的内容：\n",
    "r_velocity 根旋转\n",
    "l_velocity 根线速度\n",
    "root_y 高度\n",
    "ric_data 全局关节位置\n",
    "rot_data 局部关节旋转\n",
    "local_vel 局部线速度\n",
    "feet_l\n",
    "feet_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smpl2humanml3d\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import joblib\n",
    "\n",
    "# from common.skeleton import Skeleton\n",
    "from common.quaternion import (\n",
    "    qrot_np, qmul_np, qinv_np, qbetween_np, qfix, quaternion_to_cont6d_np\n",
    ")\n",
    "# from paramUtil import t2m_raw_offsets, t2m_kinematic_chain\n",
    "\n",
    "# # 与 [motion_representation.ipynb](e:\\szu\\2025-11\\motion_representation.ipynb) 保持一致的索引设置\n",
    "# # Lower legs\n",
    "# l_idx1, l_idx2 = 5, 8\n",
    "# Right/Left foot\n",
    "fid_r, fid_l = 8, 7\n",
    "# # Face direction index: r_hip, l_hip, sdr_r, sdr_l\n",
    "face_joint_indx = [2, 1, 17, 16]\n",
    "# # l_hip, r_hip\n",
    "# r_hip, l_hip = 2, 1\n",
    "\n",
    "joints_num = 22\n",
    "\n",
    "# T2M 骨架\n",
    "skeleton = joblib.load(\"test3.pkl\")\n",
    "offsets = torch.from_numpy(skeleton[\"offsets\"]) #(J,3)\n",
    "parents = skeleton[\"parents\"] #(J)\n",
    "\n",
    "def forward_kinematics_np(quat, trans):\n",
    "    \"\"\"\n",
    "    输入:\n",
    "        quat: (T, J, 4) 四元数表示的关节旋转\n",
    "        trans: (T, 3) 根关节平移\n",
    "    输出:\n",
    "        positions: (T, J, 3) 全局关节位置\n",
    "    \"\"\"\n",
    "    T, J, _ = quat.shape\n",
    "    positions = np.zeros((T, J, 3), dtype=np.float32)\n",
    "    # 计算每个关节的全局位置\n",
    "    for t in range(T):\n",
    "        for j in range(J):\n",
    "            if j == 0:\n",
    "                positions[t, j] = trans[t]\n",
    "            else:\n",
    "                positions[t, j] = positions[t, parents[j]] + offsets[j]\n",
    "    return positions\n",
    "\n",
    "def aa_to_quat_wxyz(aa):\n",
    "    \"\"\"\n",
    "    axis-angle -> quaternion (w,x,y,z)\n",
    "    aa: (T, J, 3)\n",
    "    \"\"\"\n",
    "    T, J, _ = aa.shape\n",
    "    q_xyzw = R.from_rotvec(aa.reshape(-1, 3)).as_quat()  # (N,4) -> [x,y,z,w]\n",
    "    q_xyzw = q_xyzw.reshape(T, J, 4)\n",
    "    # 转为 (w,x,y,z)\n",
    "    q_wxyz = np.concatenate([q_xyzw[..., 3:4], q_xyzw[..., 0:3]], axis=-1).astype(np.float32)\n",
    "    return q_wxyz\n",
    "\n",
    "def fk_smpl22_positions(trans, poses_axis_angle):\n",
    "    \"\"\"\n",
    "    使用 T2M Skeleton 做前向运动学，得到全局关节位置。\n",
    "    trans: (T,3) in meters\n",
    "    poses_axis_angle: (T, 22*3) axis-angle\n",
    "    return:\n",
    "      positions: (T, 22, 3)\n",
    "    \"\"\"\n",
    "    T = trans.shape[0]\n",
    "    aa = poses_axis_angle.reshape(T, joints_num, 3).astype(np.float32)\n",
    "    quat_params = aa_to_quat_wxyz(aa)  # (T,22,4)\n",
    "\n",
    "    positions = forward_kinematics_np(quat_params, trans.astype(np.float32))  # (T,22,3)\n",
    "    return positions\n",
    "\n",
    "def foot_detect(positions, thres):\n",
    "    \"\"\"\n",
    "    单点接触检测：每只脚只用一个关节的速度判定。\n",
    "    \"\"\"\n",
    "    th2 = thres ** 2\n",
    "    v_l = positions[1:, fid_l, :] - positions[:-1, fid_l, :]\n",
    "    v_r = positions[1:, fid_r, :] - positions[:-1, fid_r, :]\n",
    "\n",
    "    v2_l = np.sum(v_l ** 2, axis=-1, keepdims=True)  # (T-1,1)\n",
    "    v2_r = np.sum(v_r ** 2, axis=-1, keepdims=True)  # (T-1,1)\n",
    "\n",
    "    feet_l = (v2_l < th2).astype(np.float32)\n",
    "    feet_r = (v2_r < th2).astype(np.float32)\n",
    "\n",
    "    return feet_l, feet_r\n",
    "\n",
    "def _safe_norm(v, eps=1e-8):\n",
    "    n = np.linalg.norm(v, axis=-1, keepdims=True)\n",
    "    return v / np.maximum(n, eps)\n",
    "\n",
    "def _root_orientation_from_positions(frame_pos, face_joint_indx):\n",
    "    # frame_pos： (J,3)\n",
    "    # 用髋+肩的 across 定根坐标系：x=across, z=cross(up,x), y=cross(z,x)\n",
    "    # x朝前，z朝右，y朝上\n",
    "    r_hip, l_hip, sdr_r, sdr_l = face_joint_indx\n",
    "    across = frame_pos[r_hip] - frame_pos[l_hip] + frame_pos[sdr_r] - frame_pos[sdr_l]\n",
    "    x = _safe_norm(across)\n",
    "    up = np.array([0.0, 1.0, 0.0], dtype=np.float32)\n",
    "    z = _safe_norm(np.cross(up, x))\n",
    "    y = _safe_norm(np.cross(z, x))\n",
    "    Rm = np.stack([x, y, z], axis=1)  # 列为基\n",
    "    q_xyzw = R.from_matrix(Rm).as_quat()  # x,y,z,w\n",
    "    q_wxyz = np.concatenate([q_xyzw[3:4], q_xyzw[:3]], axis=0).astype(np.float32)\n",
    "    return q_wxyz  # (4,)\n",
    "\n",
    "def inverse_kinematics_np(positions, face_joint_indx, smooth_forward=False):\n",
    "    \"\"\"\n",
    "    从全局关节位置 positions(T,J,3) 和静态 offsets(J,3)、parents(J) 恢复局部四元数 quat_local(T,J,4)\n",
    "    思路：逐关节让 parent 坐标系下的 offset 向量旋到当前骨向量；转过去所需的最小旋转就是该关节的局部四元数\n",
    "    \"\"\"\n",
    "    T, J, _ = positions.shape\n",
    "    quat_local = np.zeros((T, J, 4), dtype=np.float32)\n",
    "    quat_global = np.zeros((T, J, 4), dtype=np.float32)\n",
    "\n",
    "    for t in range(T):\n",
    "        root_quat = _root_orientation_from_positions(positions[t], face_joint_indx) #wxyz\n",
    "        quat_local[t, 0] = root_quat\n",
    "        quat_global[t, 0] = root_quat\n",
    "\n",
    "        for j in range(1, J):\n",
    "            parent = parents[j]\n",
    "            parent_quat = quat_global[t, parent]\n",
    "            parent_quat_inv = qinv_np(parent_quat[None, :])[0]\n",
    "\n",
    "            bone_dir = positions[t, j] - positions[t, parent]  # (3,)\n",
    "            bone_dir_local = qrot_np(parent_quat_inv[None, :], bone_dir[None, :])[0]\n",
    "            offset = offsets[j].numpy()\n",
    "            offset_norm = np.linalg.norm(offset)\n",
    "            if offset_norm < 1e-8:\n",
    "                quat_rel = np.array([1.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "            else:\n",
    "                target_dir = bone_dir_local / np.linalg.norm(bone_dir_local) * offset_norm\n",
    "                quat_rel = qbetween_np(offset[None, :], target_dir[None, :])[0]  # (4,)\n",
    "            quat_local[t, j] = quat_rel\n",
    "            quat_global[t, j] = qmul_np(parent_quat[None, :], quat_rel[None, :])[0]\n",
    "\n",
    "    return quat_local\n",
    "\n",
    "\n",
    "def get_cont6d_params(positions):\n",
    "    \"\"\"\n",
    "    复用 HumanML3D 的 IK + cont6d 生成方式：\n",
    "      - IK 得到每帧关节四元数（smooth_forward=True）\n",
    "      - 转连续6D\n",
    "      - 根线速度/角速度\n",
    "    \"\"\"\n",
    "    # skel = Skeleton(n_raw_offsets, kinematic_chain, \"cpu\")\n",
    "    # (T, J, 4)\n",
    "    # quat_params = skel.inverse_kinematics_np(positions, face_joint_indx, smooth_forward=True)\n",
    "    quat_params = inverse_kinematics_np(positions)\n",
    "    # 修正四元数\n",
    "    quat_params = qfix(quat_params)\n",
    "\n",
    "    cont_6d_params = quaternion_to_cont6d_np(quat_params)  # (T, J, 6)\n",
    "\n",
    "    r_rot = quat_params[:, 0].copy()  # (T,4) root quat\n",
    "    '''Root Linear Velocity'''\n",
    "    velocity = (positions[1:, 0] - positions[:-1, 0]).copy()  # (T-1,3)\n",
    "    velocity = qrot_np(r_rot[1:], velocity)\n",
    "    '''Root Angular Velocity'''\n",
    "    r_velocity = qmul_np(r_rot[1:], qinv_np(r_rot[:-1]))  # (T-1,4)\n",
    "\n",
    "    return cont_6d_params, r_velocity, velocity, r_rot\n",
    "\n",
    "def smplnpz_to_data(npz_path, out_vec_dir, out_joints_dir=None, feet_thre=0.002):\n",
    "    \"\"\"\n",
    "    从 SMPL npz(trans, poses) 生成 HumanML3D data 并保存 .npy\n",
    "    \"\"\"\n",
    "    os.makedirs(out_vec_dir, exist_ok=True)\n",
    "    if out_joints_dir is not None:\n",
    "        os.makedirs(out_joints_dir, exist_ok=True)\n",
    "\n",
    "    npz = np.load(npz_path)\n",
    "    trans = npz[\"trans\"].astype(np.float32)           # (T,3)\n",
    "    poses = npz[\"poses\"].astype(np.float32)           # (T*24,3)\n",
    "    T = trans.shape[0]\n",
    "    poses = poses.reshape(T, 24, 3)[:, :22, :3]\n",
    "    poses = poses.reshape(T, -1)                      # (T, 22*3) 轴角\n",
    "\n",
    "    # 1) FK 得到原始全局关节位置\n",
    "    positions = fk_smpl22_positions(trans, poses)     # (T,22,3)\n",
    "\n",
    "    # 2) 放到地面\n",
    "    floor_height = positions.min(axis=0).min(axis=0)[1]\n",
    "    positions[:, :, 1] -= floor_height\n",
    "\n",
    "    # 3) XZ 原点\n",
    "    root_pos_init = positions[0]\n",
    "    root_pose_init_xz = root_pos_init[0] * np.array([1, 0, 1], dtype=np.float32)\n",
    "    positions = positions - root_pose_init_xz\n",
    "\n",
    "    # # 4) 初始统一朝向 Z+\n",
    "    # r_hip_i, l_hip_i, sdr_r_i, sdr_l_i = face_joint_indx\n",
    "    # across1 = root_pos_init[r_hip_i] - root_pos_init[l_hip_i]\n",
    "    # across2 = root_pos_init[sdr_r_i] - root_pos_init[sdr_l_i]\n",
    "    # across = across1 + across2\n",
    "    # across = across / np.linalg.norm(across, axis=-1, keepdims=True)\n",
    "    # forward_init = np.cross(np.array([[0, 1, 0]], dtype=np.float32), across, axis=-1)\n",
    "    # forward_init = forward_init / np.linalg.norm(forward_init, axis=-1, keepdims=True)\n",
    "    # target = np.array([[0, 0, 1]], dtype=np.float32)\n",
    "    # root_quat_init = qbetween_np(forward_init, target)\n",
    "    # root_quat_init = np.ones(positions.shape[:-1] + (4,), dtype=np.float32) * root_quat_init\n",
    "    # positions = qrot_np(root_quat_init, positions)\n",
    "\n",
    "    # # 5) 作为 new ground truth positions\n",
    "    global_positions = positions.copy()\n",
    "\n",
    "    # 6) 脚接触\n",
    "    feet_l, feet_r = foot_detect(positions, feet_thre)\n",
    "\n",
    "    # 7) cont6d / root 速度 等\n",
    "    cont_6d_params, r_velocity_q, velocity, r_rot = get_cont6d_params(positions)\n",
    "\n",
    "    # 8) RIFKE（根局部化 + 用 r_rot 对齐所有帧到根朝向坐标系）\n",
    "    def get_rifke(pos):\n",
    "        pos = pos.copy()\n",
    "        pos[..., 0] -= pos[:, 0:1, 0]\n",
    "        pos[..., 2] -= pos[:, 0:1, 2]\n",
    "        return qrot_np(np.repeat(r_rot[:, None], pos.shape[1], axis=1), pos)\n",
    "    positions_rifke = get_rifke(positions)\n",
    "\n",
    "    # 9) 构建 data 向量（与motion_representation.ipynb一致）\n",
    "    root_y = positions[:, 0, 1:2]  # (T,1)\n",
    "    r_velocity = np.arcsin(r_velocity_q[:, 2:3])      # (T-1,1) 取 y 轴分量\n",
    "    l_velocity = velocity[:, [0, 2]]                  # (T-1,2)\n",
    "    root_data = np.concatenate([r_velocity, l_velocity, root_y[:-1]], axis=-1)  # (T-1,4)\n",
    "\n",
    "    rot_data = cont_6d_params[:, 1:].reshape(len(cont_6d_params), -1)           # (T, (J-1)*6)\n",
    "    ric_data = positions_rifke[:, 1:].reshape(len(positions_rifke), -1)         # (T, (J-1)*3)\n",
    "\n",
    "    local_vel = qrot_np(np.repeat(r_rot[:-1, None], global_positions.shape[1], axis=1),\n",
    "                        global_positions[1:] - global_positions[:-1])\n",
    "    local_vel = local_vel.reshape(len(local_vel), -1)                            # (T-1, J*3)\n",
    "\n",
    "    data = root_data\n",
    "    data = np.concatenate([data, ric_data[:-1]], axis=-1)\n",
    "    data = np.concatenate([data, rot_data[:-1]], axis=-1)\n",
    "    data = np.concatenate([data, local_vel], axis=-1)\n",
    "    data = np.concatenate([data, feet_l, feet_r], axis=-1)                      # (T-1, ...)\n",
    "\n",
    "    # 保存\n",
    "    base = os.path.splitext(os.path.basename(npz_path))[0]\n",
    "    out_vec_path = os.path.join(out_vec_dir, base + \".npy\")\n",
    "    np.save(out_vec_path, data)\n",
    "\n",
    "    if out_joints_dir is not None:\n",
    "        # 可选：保存用 recover_from_ric 可重建的 joints（用于自检）\n",
    "        # 这里直接保存 positions（对齐后）\n",
    "        out_joints_path = os.path.join(out_joints_dir, base + \".npy\")\n",
    "        np.save(out_joints_path, positions.astype(np.float32))\n",
    "\n",
    "    print(f\"[OK] {base}: data {data.shape}, positions {positions.shape}\")\n",
    "    return data, positions, global_positions, l_velocity\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入：由 BVH 转来的 SMPL npz（键：trans, poses）\n",
    "    smpl_npz = r\"D:\\fsy\\project\\kdae\\F01A1V1.npz\"\n",
    "    # 输出目录：data（HumanML3D/new_joint_vecs 风格）和可选 joints\n",
    "    out_vec_dir = \"./kdaee/new_joint_vecs/\"\n",
    "    out_joints_dir = \"./kdaee/new_joints/\"\n",
    "\n",
    "    smplnpz_to_data(smpl_npz, out_vec_dir, out_joints_dir, feet_thre=0.002)\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
