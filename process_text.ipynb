{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c1af4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#批量把文本描述对应生成到单个txt文件 一行描述\n",
    "# text descriptions\n",
    "import os\n",
    "import json\n",
    "total_des=r\"F:\\fsy\\project\\kae_process\\kae_text\\sad.json\"\n",
    "data = r\"F:\\fsy\\project\\kae_process\\sad\\all.txt\"\n",
    "text_dir = r\"F:\\fsy\\project\\kae_process\\kae_text\\sad\"\n",
    "os.makedirs(text_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "with open(total_des,\"r\",encoding=\"utf-8\") as f:\n",
    "    all_texts = json.load(f)\n",
    "with open(data,\"r\") as f:\n",
    "    lines = [ln.strip() for ln in f.readlines()]\n",
    "\n",
    "assert len(lines) == len(all_texts), f\"数量对不上: {len(lines)} vs {len(all_texts)}\"\n",
    "    \n",
    "for idx, name in enumerate(lines):\n",
    "    descriptions = [all_texts[idx]]  # 未来如果变成 list[list[str]]，直接 = all_texts[idx] 即可\n",
    "    out_file = os.path.join(text_dir, name + \".txt\")\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        for desc in descriptions:\n",
    "            out_f.write(desc + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7492bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#多行描述\n",
    "import os\n",
    "import json\n",
    "\n",
    "data = r\"F:\\fsy\\project\\kae_process\\sad\\all.txt\"\n",
    "text_dir = r\"F:\\fsy\\project\\kae_process\\kae_text\\sad\"\n",
    "os.makedirs(text_dir, exist_ok=True)\n",
    "\n",
    "json_paths = [\n",
    "    r\"F:\\fsy\\project\\kae_process\\kae_text\\sad1.json\",\n",
    "    r\"F:\\fsy\\project\\kae_process\\kae_text\\sad2.json\",\n",
    "    r\"F:\\fsy\\project\\kae_process\\kae_text\\sad3.json\",\n",
    "    r\"F:\\fsy\\project\\kae_process\\kae_text\\sad4.json\",\n",
    "]\n",
    "\n",
    "# 读取 4 个 json，每个都是 list[str]\n",
    "all_lists = []\n",
    "for jp in json_paths:\n",
    "    with open(jp, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_lists.append(json.load(f))\n",
    "\n",
    "# 简单检查长度一致\n",
    "lengths = [len(lst) for lst in all_lists]\n",
    "assert len(set(lengths)) == 1, f\"4 个 json 长度不一致: {lengths}\"\n",
    "\n",
    "with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "    names = [ln.strip() for ln in f.readlines()]\n",
    "\n",
    "assert len(names) == lengths[0], f\"all.txt 数量与 json 不一致: {len(names)} vs {lengths[0]}\"\n",
    "\n",
    "for idx, name in enumerate(names):\n",
    "    # 取出同一 index 的四条描述\n",
    "    descs = [lst[idx] for lst in all_lists]  # list[str]，长度 4\n",
    "\n",
    "    # 写一个 txt，4 句各占一行（或你想要的格式）\n",
    "    out_file = os.path.join(text_dir, name + \".txt\")\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        for d in descs:\n",
    "            out_f.write(d + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276acd69",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#分词 pos\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def pos_tagging(text,start_time=0.0,end_time=0.0):\n",
    "    \"\"\"\n",
    "    纯文本转pos标注格式\n",
    "    输入：\"a man kicks something or someone with his right foot\"\n",
    "    输出：\"a/DET man/NOUN kicks/VERB something/PRON or/CCONJ someone/PRON with/ADP his/PRON right/ADJ foot/NOUN#0.0#0.0\"\n",
    "    \"\"\"    \n",
    "    doc = nlp(text.lower())\n",
    "    tagged = []\n",
    "    for token in doc:\n",
    "        pos_map = {\n",
    "            'ADJ': 'ADJ',\n",
    "            'ADP': 'ADP',\n",
    "            'ADV': 'ADV',\n",
    "            'AUX': 'AUX',\n",
    "            'CONJ': 'CCONJ',\n",
    "            'CCONJ': 'CCONJ',\n",
    "            'DET': 'DET',\n",
    "            'INTJ': 'INTJ',\n",
    "            'NOUN': 'NOUN',\n",
    "            'NUM': 'NUM',\n",
    "            'PART': 'PART',\n",
    "            'PRON': 'PRON',\n",
    "            'PROPN': 'PROPN',\n",
    "            'PUNCT': 'PUNCT',\n",
    "            'SCONJ': 'SCONJ',\n",
    "            'SYM': 'SYM',\n",
    "            'VERB': 'VERB',\n",
    "            'X': 'X'\n",
    "        }\n",
    "        pos = pos_map.get(token.pos_, 'X')\n",
    "        tagged.append(f\"{token.text}/{pos}\")\n",
    "    tagged_text = ' '.join(tagged) + f\"#{start_time}#{end_time}\"\n",
    "    return tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a75d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "text_dir = r\"F:\\fsy\\project\\kae_process\\kae_text\\sad\"\n",
    "\n",
    "for f in os.listdir(text_dir):\n",
    "    if f.endswith(\".txt\"):\n",
    "        file_path = os.path.join(text_dir, f)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as in_f:\n",
    "            lines = [ln.strip() for ln in in_f.readlines() if ln.strip()]\n",
    "\n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            tagged_line = pos_tagging(line)\n",
    "\n",
    "            # 如果原句末尾不是句号，先补一个句号作为分隔\n",
    "            if not line.endswith(\".\"):\n",
    "                line_with_sep = line + \".\"\n",
    "            else:\n",
    "                line_with_sep = line\n",
    "\n",
    "            # 同一行写：原句(+可能补的句号) + POS\n",
    "            new_lines.append(f\"{line_with_sep}{tagged_line}\\n\")\n",
    "\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as out_f:\n",
    "            out_f.writelines(new_lines)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
